{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdaabb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hatma/anaconda3/envs/top2vec/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from top2vec import Top2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac26673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " json file (before preprocessing) = \n",
      "                                                     t  \\\n",
      "0                             Movie Coverage - YouTube   \n",
      "1       Marvel Studios Celebrates The Movies - YouTube   \n",
      "2                       FRESH Movie Trailers - YouTube   \n",
      "3                           Movie: The Movie - YouTube   \n",
      "4    Tippu Hindi Dubbed Full Movie | Satya Karthik,...   \n",
      "..                                                 ...   \n",
      "193  Amazon Music Unlimited | 70 million songs ad-f...   \n",
      "194                  Music Ally Is A Knowledge Company   \n",
      "195                              Music - Rolling Stone   \n",
      "196  MusicRadar: Music Gear, Equipment, News, Tutor...   \n",
      "197                Get started | Learning Music (Beta)   \n",
      "\n",
      "                                                     a  \\\n",
      "0    https://www.youtube.com/channel/UCwYzZs_hwA6Nd...   \n",
      "1      https://www.youtube.com/watch%3Fv%3DQdpxoFcdORI   \n",
      "2         https://www.youtube.com/c/FreshMovieTrailers   \n",
      "3      https://www.youtube.com/watch%3Fv%3Dw3NwB9PLxss   \n",
      "4      https://www.youtube.com/watch%3Fv%3DVf3KQa5jh4M   \n",
      "..                                                 ...   \n",
      "193             https://www.amazon.com/music/unlimited   \n",
      "194                             https://musically.com/   \n",
      "195                https://www.rollingstone.com/music/   \n",
      "196                        https://www.musicradar.com/   \n",
      "197                 https://learningmusic.ableton.com/   \n",
      "\n",
      "                                        c  \\\n",
      "0               www.youtube.com › channel   \n",
      "1                 www.youtube.com › watch   \n",
      "2    www.youtube.com › FreshMovieTrailers   \n",
      "3                 www.youtube.com › watch   \n",
      "4                 www.youtube.com › watch   \n",
      "..                                    ...   \n",
      "193    www.amazon.com › music › unlimited   \n",
      "194                         musically.com   \n",
      "195          www.rollingstone.com › music   \n",
      "196                    www.musicradar.com   \n",
      "197             learningmusic.ableton.com   \n",
      "\n",
      "                                                     d  \n",
      "0    The best of films and movie trailers. Pick you...  \n",
      "1    Duration:     3:11    Posted:     3 days ago  ...  \n",
      "2    All NEW MOVIE TRAILERS are Here! Don't miss th...  \n",
      "3    Duration:     8:33    Posted:     26-Feb-2012 ...  \n",
      "4    Duration:     1:31:46    Posted:     1 day ago...  \n",
      "..                                                 ...  \n",
      "193  3 Months Free - Offer Terms & Conditions: This...  \n",
      "194  We have over 15 years worth of information, ex...  \n",
      "195       Music, Film, TV and Political News Coverage.  \n",
      "196  Get up to the minute news and reviews for all ...  \n",
      "197  Explore the fundamentals of music via Ableton'...  \n",
      "\n",
      "[198 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "import pandas as pd\n",
    "import json\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "\n",
    "filetype = \"json\"\n",
    "inputfile = \"mixed.json\"\n",
    "verbose = True\n",
    "\n",
    "if filetype == \"csv\":\n",
    "    # tmp = pd.read_csv(inputfile, header=None, low_memory=False)\n",
    "    tmp = dd.read_csv(inputfile, sep=';', header=None)\n",
    "    tmp2 = tmp.to_dask_array(lengths=True)\n",
    "    tmp3 = tmp2.compute()\n",
    "    tmp4 = pd.DataFrame(tmp3)\n",
    "\n",
    "    if verbose == True:\n",
    "        print(\"\\n\\n csv file (before preprocessing) = \")\n",
    "        print(tmp4)\n",
    "\n",
    "    corpus = tmp4[0].str.lower().apply(remove_stopwords).to_numpy()\n",
    "\n",
    "elif filetype == \"json\":\n",
    "    with open(inputfile) as json_file:\n",
    "        jsonfile = json.load(json_file)\n",
    "\n",
    "    tmp = pd.DataFrame(jsonfile['results'])\n",
    "\n",
    "    if verbose == True:\n",
    "        print(\"\\n\\n json file (before preprocessing) = \")\n",
    "        print(tmp)\n",
    "\n",
    "    tmp['td'] = tmp['t'] + ' ' + tmp['d']\n",
    "    corpus = tmp['td'].str.lower().apply(remove_stopwords).to_numpy()\n",
    "\n",
    "else:\n",
    "    print(\"ERROR, only accept csv or json file!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef8fdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-21 16:20:19,662 - top2vec - INFO - Pre-processing documents for training\n",
      "2022-08-21 16:20:19,675 - top2vec - INFO - Creating joint document/word embedding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate documents\n",
      "198\n",
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-21 16:20:19,947 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2022-08-21 16:20:25,762 - top2vec - INFO - Finding dense areas of documents\n",
      "2022-08-21 16:20:25,767 - top2vec - INFO - Finding topics\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTop2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/top2vec/lib/python3.10/site-packages/top2vec/Top2Vec.py:687\u001b[0m, in \u001b[0;36mTop2Vec.__init__\u001b[0;34m(self, documents, min_count, ngram_vocab, ngram_vocab_args, embedding_model, embedding_model_path, embedding_batch_size, split_documents, document_chunker, chunk_length, max_num_chunks, chunk_overlap_ratio, chunk_len_coverage_ratio, sentencizer, speed, use_corpus_file, document_ids, keep_documents, workers, tokenizer, use_embedding_model_tokenizer, umap_args, hdbscan_args, verbose)\u001b[0m\n\u001b[1;32m    684\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinding topics\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# create topic vectors\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_topic_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# deduplicate topics\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deduplicate_topics()\n",
      "File \u001b[0;32m~/anaconda3/envs/top2vec/lib/python3.10/site-packages/top2vec/Top2Vec.py:862\u001b[0m, in \u001b[0;36mTop2Vec._create_topic_vectors\u001b[0;34m(self, cluster_labels)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m unique_labels:\n\u001b[1;32m    860\u001b[0m     unique_labels\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_l2_normalize(\n\u001b[0;32m--> 862\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_vectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/top2vec/lib/python3.10/site-packages/numpy/core/shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "model = Top2Vec(documents=corpus.tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_num_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a77670",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "\n",
    "print(topic_sizes)\n",
    "print(topic_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2816528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_nums = model.get_topics(2)\n",
    "\n",
    "print(topic_words)\n",
    "print(word_scores)\n",
    "print(topic_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"music\"], num_topics=2)\n",
    "\n",
    "print(topic_words)\n",
    "print(word_scores)\n",
    "print(topic_scores)\n",
    "print(topic_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea3b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"music\"], num_topics=2)\n",
    "for topic in topic_nums:\n",
    "    model.generate_topic_wordcloud(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=1, num_docs=2)\n",
    "\n",
    "print(documents)\n",
    "print(document_scores)\n",
    "print(document_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=1, num_docs=2)\n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(f\"Document: {doc_id}, Score: {score}\")\n",
    "    print(\"-----------\")\n",
    "    print(doc)\n",
    "    print(\"-----------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_keywords(keywords=[\"music\", \"youtube\"], num_docs=5)\n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(f\"Document: {doc_id}, Score: {score}\")\n",
    "    print(\"-----------\")\n",
    "    print(doc)\n",
    "    print(\"-----------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word_scores = model.similar_words(keywords=[\"music\"], keywords_neg=[], num_words=20)\n",
    "for word, score in zip(words, word_scores):\n",
    "    print(f\"{word} {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260feb84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "top2vec",
   "language": "python",
   "name": "top2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
